<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Zero-Shot Novel View and Depth Synthesis with Multi-View Geometric Diffusion">
  <meta name="keywords" content="Diffusion Models, Few-shot View-Synthesis, Implicit Foundation Model">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Zero-Shot Novel View and Depth Synthesis with Multi-View Geometric Diffusion</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-4G7TY8JHD8"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-4G7TY8JHD8');
</script>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://zubairirshad.com">
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
        </a>

        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://www.arxiv.org/abs/2409.09896">
              GRIN
            </a>
            <a class="navbar-item" href="https://sites.google.com/view/tri-zerodepth">
              ZeroDepth
            </a>
            <a class="navbar-item" href="https://nerf-mae.github.io/">
              NeRF-MAE
            </a>
            <a class="navbar-item" href="https://zubair-irshad.github.io/projects/neo360.html">
              NeO360
            </a>
          </div>
        </div>
      </div>

    </div>
  </nav>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h3 class="title is-1 publication-title">Zero-Shot Novel View and Depth Synthesis <br> with Multi-View Geometric Diffusion</h1>
              <!-- <div class="column is-full_width">
                <h2 class="title is-4">arXiv, 2025</h2>
              </div> -->
              <div class="is-size-5 publication-authors">

                <span class="author-block">
                  <a href="https://www.linkedin.com/in/vitorguizilini/">Vitor Guizilini</a>,</span>

                <span class="author-block">
                  <a href="https://zubairirshad.com">Muhammad Zubair Irshad</a>,</span>

                <span class="author-block">
                  <a href="https://www.dianchen.io/">Dian Chen</a>,</span>

                <span class="author-block">
                  <a href="https://home.ttic.edu/~gregory/">Greg Shakhnarovich</a>,</span>

                <span class="author-block">
                  <a href="https://www.tri.global/about-us/dr-rares-ambrus">Rares Ambrus</a></span>

              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block">Toyota Research Institute</span>
              </div>

              <div class="publication-logo">
                <sup></sup> <a href="https://www.tri.global/"><img style="width:20%; padding-right: 15px; padding-bottom: 0px; padding-top: 0px" src="assets/tri_logo_3.svg"> </a>
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- PDF Link. -->
                  <span class="link-block">
                    <a href="https://arxiv.org/pdf/2501.18804"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>
                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2501.18804"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv</span>
                    </a>
                  </span>


                  <!-- Code Link. -->
                  <span class="link-block">
                    <a href="https://mvgd.github.io/"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code (Coming Soon)</span>
                    </a>
                  </span>
                </div>

              </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero carousel">
    <div class="hero-body">
      <div class="container">
        <div id="white-carousel" class="carousel1 white-carousel">
            <div class="item item-steve" style="display: flex; flex-direction: column; align-items: center;">
            <img src="./static/images/mvg_teaser_1.png" id="mvgd" class="interpolation-image"  style="max-width: 88%; height: auto;"
            alt="Interpolate start reference image." />
          </div>
          <div class="item item-steve" style="display: flex; flex-direction: column; align-items: center;">
            <img src="./static/images/mvgd_teaser_2.png" id="mvgd" class="interpolation-image"  style="max-width: 88%; height: auto;"
            alt="Interpolate start reference image." />
          </div>
          <div class="item item-steve" style="display: flex; flex-direction: column; align-items: center;">
            <img src="./static/images/mvgd_teaser_3.png" id="mvgd" class="interpolation-image"  style="max-width: 88%; height: auto;"
            alt="Interpolate start reference image." />
          </div>
          <div class="item item-steve" style="display: flex; flex-direction: column; align-items: center;">
            <img src="./static/images/mvgd_teaser_4.png" id="mvgd" class="interpolation-image"  style="max-width: 88%; height: auto;"
            alt="Interpolate start reference image." />
          </div>
          <div class="item item-steve" style="display: flex; flex-direction: column; align-items: center;">
            <img src="./static/images/mvgd_teaser_5.png" id="mvgd" class="interpolation-image"  style="max-width: 88%; height: auto;"
            alt="Interpolate start reference image." />
          </div>
        </div>
      </div>

      <div class="text-container" style="max-width: 88%; margin: 0 auto; text-align: center; margin-top: 1rem;">
        <h2 class="subtitle" style="font-size: 1.1rem;">
          <span class="dnerf">Multi-view Geometric Diffusion (MVGD)</span> is a framework for zero-shot images and scale-consistent depth maps generation from novel<br>  viewpoints given an arbitrary number of posed input views.
        </h2>
      </div>
      
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>

              Current methods for 3D scene reconstruction from sparse posed images employ intermediate 3D representations 
              such as neural fields, voxel grids, or 3D Gaussians, to achieve multi-view consistent scene appearance and geometry.
              
            </p>
            <p>

              In this paper we introduce <span class="dnerf">Multi-view Geometric Diffusion (MVGD)</span>, a diffusion-based architecture capable of direct pixel-level 
              generation of images and depth maps from novel viewpoints, given an arbitrary number of input views. Our method uses raymap conditioning to both augment 
              visual features with spatial information from different viewpoints, 
              as well as to guide the generation of images and depth maps from novel views. A key aspect of our approach is the multi-task generation of 
              images and depth maps, using learnable task embeddings to guide the diffusion process towards specific modalities.
            </p>
            <p>
              We train this model on a collection of more than 60 million multi-view samples from publicly available datasets, and propose techniques to 
              enable efficient and consistent learning in such diverse conditions. We also propose a novel strategy that enables the efficient training of larger models by 
              incrementally fine-tuning smaller ones, with promising scaling behavior. Through extensive experiments, we report state-of-the-art results in multiple 
              novel view synthesis benchmarks, as well as multi-view stereo and video depth estimation.  
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
    </div>
  </section>

  <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
        <h2 class="title is-3"><b>Novel view and depth synthesis results using incremental conditioning.</h2>
        </b> Red cameras indicate initial conditioning views, used to generate predictions for green cameras. After each generation, the predicted image <br> is added to the set of conditioning views for future generations.
        </div>
        </div>
      <div class="container">
        <div id="results-carousel" class="carousel3 results-carousel">
          <div class="item item-steve">
            <video poster="" id="steve" autoplay muted loop width="90%">
              <source src="./videos/output_video6.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-steve">
            <video poster="" id="steve" autoplay muted loop width="90%">
              <source src="./videos/output_video3.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-steve">
            <video poster="" id="steve" autoplay muted loop width="90%">
              <source src="./videos/output_video5.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-steve">
            <video poster="" id="steve" autoplay muted loop width="90%">
              <source src="./videos/output_video7.mp4" type="video/mp4">
            </video>
          </div>

          <div class="item item-steve">
            <video poster="" id="steve" autoplay muted loop width="90%">
              <source src="./videos/output_video8.mp4" type="video/mp4">
            </video>
          </div>

          <div class="item item-steve">
            <video poster="" id="steve" autoplay muted loop width="90%">
              <source src="./videos/output_video16.mp4" type="video/mp4">
            </video>
          </div>

          <div class="item item-steve">
            <video poster="" id="steve" autoplay muted loop width="90%">
              <source src="./videos/output_video10_fast.mp4" type="video/mp4">
            </video>
          </div>

          <div class="item item-steve">
            <video poster="" id="steve" autoplay muted loop width="90%">
              <source src="./videos/output_video11_fast.mp4" type="video/mp4">
            </video>
          </div>

          <div class="item item-steve">
            <video poster="" id="steve" autoplay muted loop width="90%">
              <source src="./videos/output_video9_fast.mp4" type="video/mp4">
            </video>
          </div>

          <div class="item item-steve">
            <video poster="" id="steve" autoplay muted loop width="90%">
              <source src="./videos/output_video15.mp4" type="video/mp4">
            </video>
          </div>

          <div class="item item-steve">
            <video poster="" id="steve" autoplay muted loop width="90%">
              <source src="./videos/output_video2.mp4" type="video/mp4">
            </video>
          </div>

          <div class="item item-steve">
            <video poster="" id="steve" autoplay muted loop width="90%">
              <source src="./videos/output_video4.mp4" type="video/mp4">
            </video>
          </div>

          <div class="item item-steve">
            <video poster="" id="steve" autoplay muted loop width="90%">
              <source src="./videos/output_video1.mp4" type="video/mp4">
            </video>
          </div>

          <div class="item item-steve">
            <video poster="" id="steve" autoplay muted loop width="90%">
              <source src="./videos/output_video14.mp4" type="video/mp4">
            </video>
          </div>

          <div class="item item-steve">
            <video poster="" id="steve" autoplay muted loop width="90%">
              <source src="./videos/output_video12.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section>

  <br>
  <br>

  <section class="hero">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
        <h2 class="title is-3">Accumulated Pointcloud result</h2>
      </b> We obtained these accumulated pointclouds by generating novel images and depth maps from various viewpoints (black
      cameras), <br> using the same conditioning views (colored cameras), and stacking them together without any post-processing.
        </div>
        </div>

      <div class="container">

          <img src="./static/images/collage_accumulated_2x4_with_spacing.png" alt="Pointcloud 1" style="width: 88%; height: auto; display: block; margin: 0 auto;">
        </div>

      </div>
    </div>
  </section>

  <section class="hero">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
        <h2 class="title is-3">Stacked Pointcloud Qualitative Result</h2>
      To highlight the multi-view consistency of our method, predicted colored pointclouds from all novel viewpoints are stacked
      together for visualization <br> without any post-processing. Red cameras are used as conditioning views, and novel
      images and depth maps are generated from green cameras. <br>
        </div>
      </div>
      <div class="container">

        <div>
          <img src="./static/images/collage_random_incremental2_3x4.png" alt="Pointcloud2" style="width: 88%; height: auto; display: block; margin: 0 auto;">
        </div>

      </div>
    </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <p>
        If you find our paper useful, please consider citing:
      </p>
      <pre><code>@misc{guizilini2025zeroshotnovelviewdepth,
        title={Zero-Shot Novel View and Depth Synthesis with Multi-View Geometric Diffusion}, 
        author={Vitor Guizilini and Muhammad Zubair Irshad and Dian Chen and Greg Shakhnarovich and Rares Ambrus},
        year={2025},
        eprint={2501.18804},
        archivePrefix={arXiv},
        primaryClass={cs.CV},
        url={https://arxiv.org/abs/2501.18804}, 
  }
</code></pre>
    </div>
  </section>

  <footer class="footer">
    <div align="center" class="container">
        <div class="columns is-centered">
            <div class="content is-small">
                This website templated is borrowed from <a
                    href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
            </div>
        </div>
    </div>
</footer>

</body>

</html>
